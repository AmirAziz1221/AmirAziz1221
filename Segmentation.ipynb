{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirAziz1221/AmirAziz1221/blob/main/Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeY1n-e2Ou0O",
        "outputId": "1d0c39e7-8e8f-48d3-abb9-4969b9b74117"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Water Segmentation Model"
      ],
      "metadata": {
        "id": "mkURGMJRFe0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a1nqy2p6zii0"
      },
      "outputs": [],
      "source": [
        "# Install and Import Libraries\n",
        "!pip install ultralytics roboflow\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "\n",
        "\n",
        "# Train the YOLOv8 segmentation model\n",
        "model = YOLO(\"yolov8n-seg.pt\")  # YOLOv8 segmentation pre-trained model\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data=f\"/content/drive/MyDrive/Water Segmentation/Water Segmenting v1.v1-version-1.yolov11/data.yaml\",  # Path to the dataset configuration\n",
        "    epochs=20,                             # Increase epochs for better performance\n",
        "    imgsz=640,                             # Image size\n",
        "    device=0                               # Use GPU if available\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save this model"
      ],
      "metadata": {
        "id": "lN3EIq1IItHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"26_best_water_segmentation_model.pt\")"
      ],
      "metadata": {
        "id": "VHKyaXgkI0Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Model on a Video"
      ],
      "metadata": {
        "id": "c7ZqtN4NFSUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO  # Make sure to import the YOLO model from the appropriate library\n",
        "\n",
        "# Load the trained model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = YOLO(\"26_best_water_segmentation_model.pt\")\n",
        "\n",
        "# Path to the input video\n",
        "video_path = \"/content/drive/MyDrive/Water Segmentation/combine video.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Output video writer setup\n",
        "output_path = \"/content/drive/MyDrive/Water Segmentation/26_segmented_output.mp4\"\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Original video FPS\n",
        "frame_width, frame_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "# Process each frame\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess the frame\n",
        "    input_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = model.predict(input_frame, imgsz=640)  # Run inference\n",
        "\n",
        "    # Check if masks are available\n",
        "    if results[0].masks is not None:\n",
        "        # Extract the first segmentation mask\n",
        "        mask = results[0].masks.data[0].cpu().numpy()  # Get the first mask\n",
        "        mask = (mask > 0.5).astype(np.uint8) * 255  # Binarize mask\n",
        "\n",
        "        # Overlay the mask on the frame\n",
        "        overlay = cv2.addWeighted(frame, 0.8, cv2.merge((mask, mask, mask)), 0.2, 0)\n",
        "    else:\n",
        "        # If no mask is detected, use the original frame\n",
        "        overlay = frame\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    out.write(overlay)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"Video processing and saving completed.\")"
      ],
      "metadata": {
        "id": "3xN2WTzBFWcL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Short video processing"
      ],
      "metadata": {
        "id": "buq45bd5G1IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load the trained model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = YOLO(\"26_best_water_segmentation_model.pt\")  # Load trained model\n",
        "\n",
        "# Path to the input video\n",
        "video_path = \"/content/drive/MyDrive/Water Segmentation/combine video.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Output video writer setup\n",
        "output_path = \"/content/drive/MyDrive/Water Segmentation/short_segmented_output.mp4\"\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Original video FPS\n",
        "frame_width, frame_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "# Define frame skipping parameters\n",
        "frame_skip_rate = 1000  # Process every 1000th frame\n",
        "frame_counter = 0       # Initialize frame counter\n",
        "processed_frames = 0    # Keep track of processed frames\n",
        "max_frames_to_process = fps * 60 * 5  # Target duration: 5 minutes (based on FPS)\n",
        "\n",
        "# Process the video\n",
        "while cap.isOpened() and processed_frames < max_frames_to_process:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_counter += 1\n",
        "    if frame_counter % frame_skip_rate != 0:\n",
        "        continue\n",
        "\n",
        "    # Preprocess the frame\n",
        "    input_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = model.predict(input_frame, imgsz=640)  # Run inference\n",
        "\n",
        "    # Check if masks are detected\n",
        "    if results[0].masks is not None:\n",
        "        mask = results[0].masks.data[0].cpu().numpy()  # Get the first mask\n",
        "        mask = (mask > 0.5).astype(np.uint8) * 255  # Binarize mask\n",
        "\n",
        "        # Overlay the mask on the frame\n",
        "        overlay = cv2.addWeighted(frame, 0.8, cv2.merge((mask, mask, mask)), 0.2, 0)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(overlay)\n",
        "        processed_frames += 1\n",
        "    else:\n",
        "        print(f\"No segmentation mask detected for frame {frame_counter}.\")\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"Short video processing and saving completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOsTadKgG2R4",
        "outputId": "05f0d89b-c04a-45f2-87db-6eec17cd435a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 3.7ms preprocess, 15.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 1000.\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 3.4ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 2000.\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 4.0ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 3000.\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 4.6ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 4000.\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 5.9ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 5000.\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 3.5ms preprocess, 17.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 6000.\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 3.2ms preprocess, 18.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 7000.\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 4.7ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 8000.\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 6.6ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 9000.\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 14.4ms preprocess, 18.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 10000.\n",
            "\n",
            "0: 384x640 (no detections), 23.4ms\n",
            "Speed: 3.3ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 11000.\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 12000.\n",
            "\n",
            "0: 384x640 (no detections), 27.1ms\n",
            "Speed: 3.4ms preprocess, 27.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 13000.\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 14000.\n",
            "\n",
            "0: 384x640 (no detections), 30.0ms\n",
            "Speed: 3.4ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 15000.\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 16000.\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 17000.\n",
            "\n",
            "0: 384x640 (no detections), 24.7ms\n",
            "Speed: 3.6ms preprocess, 24.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 18000.\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 4.2ms preprocess, 16.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 19000.\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 20000.\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 21000.\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 3.1ms preprocess, 16.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 22000.\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 6.3ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No segmentation mask detected for frame 23000.\n",
            "Short video processing and saving completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9S_0WwFIMtVc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1Qxn1h0-MLKSl8-uwTx6UvcjpEeNqErkI",
      "authorship_tag": "ABX9TyPqzys11gIGQjOB4u3TZsO9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}